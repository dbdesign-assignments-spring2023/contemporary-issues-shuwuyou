# Contemporary Issues In Data, Tony Shu
'''
# Tesla's autopilot system pushes the discussion of AI driving into crux
In this document, I talk about how Tesla's autopilot system is a big step forward on AI system that bases on real-time processed data, yet it also generates underlying problems with the system in terms of driver. The two articles that I choose stand on opposite view on Tesla's autopilot system, which both provide valid contexts.

## Article 1
In Nadeem Sarwar's article [Tesla's Latest Self-Driving Update Is A Game-Changer](https://www.slashgear.com/868855/teslas-latest-self-driving-update-is-a-game-changer/), he talked about Tesla's new update version of Full Self-Driving (FSD) software updates. It is an AI system that bases on video data that were gathered from Tesla's cameras as well as other important data to generate a self-driving system. This new version contains 180,000 new video recordings to the training data cache, which, according to Tesla, improves the accuracy of the lane prediction and the comfortability of left turn motion of cars as well as better identifying the yellow traffic light and pedestrians and cyclists.

Through out these lines, Sarwar holds an optimistic and positive opinion toward tesla's FSD. Its frequent updates through setting new training datasets and experiments help drivers gain a more reliable and comfortable self-driving experience. The idea of data here is that it benefits Tesla and boosts the performances of the FSD system, which re-defines the meaning of driving and cars.

## Article 2
In Christopher Cox's article [Elon Muskâ€™s Appetite for Destruction](https://www.nytimes.com/2023/01/17/magazine/tesla-autopilot-self-driving-elon-musk.html), Cox draws a more radical and aximatic problems that Tesla's self-driving system had. This start off by saying that flashing lights and stationary objects trick AI, which made the FSD unable to identify objects like police cruisers. The cases of problematic performance of AI lead to lawsuits toward Tesla. Yet, Tesla consistently inflated consumer expectations and played down the dangers involved, said Cox. 

This article peels off the candycoat of the first article and demonstrate many problems regarding AI and machine learning. They are not that reliable and useful. Based on the logic of trained datasets, AI cannot predict a new senario when new element combinitions occur, in this case, the police's light and cruisers. Although data can provide use plenty of insights, it unaviodably makes mistakes. As the article said, Tesla's autopilot system aims to solve traffic incidents. Yet, there is at least one car crash by autopilot in the US everyday, which is the opposite of what Elon Musk wishes to see. 

Hence, based on the two articles, it is easy for people to see two different pictures, one is the paradise AI created through data and another is the tragedy AI made. Therefore, it is extremely important to understand the use of AI and the implement of data. The fundamental logic of machine learning made mistakes unavoidable--one can be rational when confronting special incidents on road yet AI can only infer from empirical datasets. 
'''